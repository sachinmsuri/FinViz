{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sachinsuri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from iexcloud.iexcloud import iexCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from prophet import Prophet\n",
    "from datetime import date\n",
    "import datetime\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "file_path = r'all-data.csv'\n",
    "\n",
    "iex = iexCloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching time series data for AAPL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>38.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>38.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>37.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>38.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-19</td>\n",
       "      <td>38.2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>228.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>231.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>219.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>213.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>220.6650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      AAPL\n",
       "0    2017-05-15   38.9250\n",
       "1    2017-05-16   38.8675\n",
       "2    2017-05-17   37.5625\n",
       "3    2017-05-18   38.1350\n",
       "4    2017-05-19   38.2650\n",
       "...         ...       ...\n",
       "1254 2022-05-09  228.0900\n",
       "1255 2022-05-10  231.7650\n",
       "1256 2022-05-11  219.7500\n",
       "1257 2022-05-12  213.8400\n",
       "1258 2022-05-13  220.6650\n",
       "\n",
       "[1259 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = iex.get_max_time_series_df('AAPL')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "#condition = df['df'] >= date.today()\n",
    "date_obj = datetime.datetime(2022, 5, 9)\n",
    "condition = df['Date'] >= date_obj\n",
    "#df = df[df['Date'] >= date_obj]\n",
    "df.loc[condition, 'AAPL'] = 1.5 * df.loc[condition, 'AAPL']\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FETCH NEWS ARTICLES FROM IEXCLOUD API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN SENTIMENT ANALYSIS MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean data\n",
    "def clean_data(df, test):\n",
    "    #turn all letters to lowercase\n",
    "    df['sentence'] = df['sentence'].str.lower()\n",
    "\n",
    "    #normalise text data & remove numbers\n",
    "    df[\"sentence\"] = df['sentence'].str.replace(\n",
    "            \"(@\\[A-Za-z]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\",''\n",
    "        )\n",
    "\n",
    "    #Remove stop words\n",
    "    df['sentence'] = df['sentence'].apply(\n",
    "            lambda x: ' '.join([word for word in x.split() if word not in (stop_words)])\n",
    "        )\n",
    "\n",
    "    df['sentence (format)'] = df['sentence'].str.split(\" \")\n",
    "    df['sentence (stemmed)'] = df['sentence (format)'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    df = df.drop(['sentence (format)'], axis=1)\n",
    "\n",
    "    df['sentence stemmed'] = df['sentence'].apply(lambda x: ''.join([str(elem) for elem in x]))\n",
    "    df = df.drop(['sentence (stemmed)'], axis=1)\n",
    "\n",
    "    if not test:\n",
    "        sentiment_score = {\n",
    "            'neutral': 0,\n",
    "            'negative': -1,\n",
    "            'positive': 1\n",
    "        }\n",
    "\n",
    "        df['sentiment'] = df['sentiment'].replace(sentiment_score)\n",
    "        df.columns = df.columns.str.replace(\" \", \"\")\n",
    "    \n",
    "        df = df.drop(['sentiment'], axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/bygxc1vx7y7c1hvcw37ff9kw0000gn/T/ipykernel_86325/2593539304.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"sentence\"] = df['sentence'].str.replace(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>according gran company plans move production r...</td>\n",
       "      <td>according gran company plans move production r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>technopolis plans develop stages area less squ...</td>\n",
       "      <td>technopolis plans develop stages area less squ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>international electronic industry company elco...</td>\n",
       "      <td>international electronic industry company elco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>new production plant company would increase ca...</td>\n",
       "      <td>new production plant company would increase ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>according company updated strategy years baswa...</td>\n",
       "      <td>according company updated strategy years baswa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>negative</td>\n",
       "      <td>london marketwatch share prices ended lower lo...</td>\n",
       "      <td>london marketwatch share prices ended lower lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rinkuskiai beer sales fell per cent million li...</td>\n",
       "      <td>rinkuskiai beer sales fell per cent million li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>negative</td>\n",
       "      <td>operating profit fell eur mn eur mn including ...</td>\n",
       "      <td>operating profit fell eur mn eur mn including ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>negative</td>\n",
       "      <td>net sales paper segment decreased eur mn secon...</td>\n",
       "      <td>net sales paper segment decreased eur mn secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>negative</td>\n",
       "      <td>sales finland decreased january sales outside ...</td>\n",
       "      <td>sales finland decreased january sales outside ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                           sentence  \\\n",
       "0      neutral  according gran company plans move production r...   \n",
       "1      neutral  technopolis plans develop stages area less squ...   \n",
       "2     negative  international electronic industry company elco...   \n",
       "3     positive  new production plant company would increase ca...   \n",
       "4     positive  according company updated strategy years baswa...   \n",
       "...        ...                                                ...   \n",
       "4841  negative  london marketwatch share prices ended lower lo...   \n",
       "4842   neutral  rinkuskiai beer sales fell per cent million li...   \n",
       "4843  negative  operating profit fell eur mn eur mn including ...   \n",
       "4844  negative  net sales paper segment decreased eur mn secon...   \n",
       "4845  negative  sales finland decreased january sales outside ...   \n",
       "\n",
       "                                       sentence stemmed  \n",
       "0     according gran company plans move production r...  \n",
       "1     technopolis plans develop stages area less squ...  \n",
       "2     international electronic industry company elco...  \n",
       "3     new production plant company would increase ca...  \n",
       "4     according company updated strategy years baswa...  \n",
       "...                                                 ...  \n",
       "4841  london marketwatch share prices ended lower lo...  \n",
       "4842  rinkuskiai beer sales fell per cent million li...  \n",
       "4843  operating profit fell eur mn eur mn including ...  \n",
       "4844  net sales paper segment decreased eur mn secon...  \n",
       "4845  sales finland decreased january sales outside ...  \n",
       "\n",
       "[4846 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, encoding='ISO-8859-1', names=['sentiment', 'sentence'])\n",
    "df_train = clean_data(df, True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.53      0.60       122\n",
      "     neutral       0.78      0.87      0.82       570\n",
      "    positive       0.71      0.60      0.65       278\n",
      "\n",
      "    accuracy                           0.75       970\n",
      "   macro avg       0.73      0.67      0.69       970\n",
      "weighted avg       0.75      0.75      0.74       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tfidf\n",
    "tfidf = TfidfVectorizer(max_features = 5000)\n",
    "x = df['sentence']\n",
    "y = df['sentiment']\n",
    "\n",
    "x = tfidf.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    #stratify=y,\n",
    "    random_state=1,\n",
    "    test_size =0.2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 93, 2: 6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions on test set\n",
    "ticker_symbol = 'AAPL'\n",
    "news_df = iex.get_news(ticker_symbol)\n",
    "\n",
    "x = tfidf.transform(news_df['headline'])\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "y_pred\n",
    "\n",
    "sentiment_count = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0\n",
    "}\n",
    "\n",
    "for sentiment in y_pred:\n",
    "    if sentiment == 'neutral':\n",
    "        sentiment_count[1] += 1\n",
    "    if sentiment == 'positive':\n",
    "        sentiment_count[2] += 1\n",
    "    if sentiment == 'negative':\n",
    "        sentiment_count[0] += 1 \n",
    "\n",
    "print(sentiment_count)\n",
    "weighted_average = (\n",
    "    (sentiment_count[1] * 1 +\n",
    "    sentiment_count[2] * 2 +\n",
    "    sentiment_count[0] * 0) / 100\n",
    ")\n",
    "weighted_average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN TIMESERIES FORECASTING MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_symbol = 'AAPL'\n",
    "ticker_data = iex.get_max_time_series_df(ticker_symbol)\n",
    "ticker_data = ticker_data.rename(columns = {\n",
    "    'Date': 'ds',\n",
    "    ticker_symbol: 'y'\n",
    "})\n",
    "ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"daily_seasonality\": False,\n",
    "    \"weekly_seasonality\": False,\n",
    "    \"yearly_seasonality\": True,\n",
    "    \"seasonality_mode\": \"multiplicative\",\n",
    "    \"growth\": \"logistic\"\n",
    "}\n",
    "\n",
    "\n",
    "model = Prophet(**model_params)\n",
    "ticker_data[\"cap\"] = ticker_data['y'].max() + ticker_data['y'].std() * 0.05\n",
    "\n",
    "model.fit(ticker_data)\n",
    "\n",
    "future = model.make_future_dataframe(periods=100)\n",
    "future[\"cap\"] = ticker_data[\"cap\"].max()\n",
    "\n",
    "forecast = model.predict(future)\n",
    "print(forecast)\n",
    "model.plot_components(forecast)\n",
    "model.plot(forecast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINE TIMESERIES FORECASTING WITH SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3e8fe01098a72a2c37ee9d148af3baa6904cacc348b77d48fe6e6e54534ce65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('finviz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
